---
layout: post
title: "AWS"
published: true
---

Progress: 12/65

## AWS Services

- **AWS AI Service Cards**: documentation for AWS AI services
- **AWS CloudTrail**: logs AWS service activity (including API calls)
- **AWS Config**: overview of AWS resource configurations
- **AWS Lambda**: serverless compute service
- **AWS Trusted Advisor**: provide recommendations to improve account (e.g. cost savings)

## Amazon Services

- **Amazon Augmented AI (A2I)**: human review of ML predictions
- **Amazon CloudWatch**: logs for applications on AWS (NO API calls)
- **Amazon DocumentDB**: fully managed, MongoDB compatible, JSON document database, supports real-time vector search with low latency
- **Amazon Macie**: discover, monitor, and protect sensitive data in Amazon S3
- **Amazon OpenSearch Service**: fully managed service for OpenSearch on AWS with vector store & similarity search
- **Amazon RDS for Oracle**: relational database with Oracle support
- **Amazon Redshift**: fully managed SQL database
- **Amazon Rekognition**: analyze visual content (image and video)
- **Amazon S3**: object storage service
- **Amazon SageMaker Clarify**: explain model responses, detect bias
- **Amazon SageMaker Ground Truth**: label data for ML model training
- **Amazon SageMaker Model Monitor**: alerts when model quality changes (data drift)
- **Amazon SageMaker Model Cards**: documentation for models (intended use, evaluation metrics)

## Terms & Definitions

- **continued pre-training**: provide unlabeled data to FM to improve domain knowledge
- **foundational model (FM)**: broader then LLM, can handle various data types
- **instruction-based fine-tuning**: use labeled examples (prompt, response pairs) to improve FM on a specific task
- **large language model (LLM)**: focus on text & language tasks
- **prompt engineering**: optimize FM inputs to generate better responses
- **prompt template**: predefined format to standardize inputs and outputs
- **retrieval augmented generation (RAG)**: technique to let LLM use information from external knowledge base
- **zero-shot learning**: make predictions without examples
- **few-shot learning**: make predictions using a few examples in prompt
- **temperature**: control randomnes of response (higher temperature -> more random)
- **top K**: # number of most-likely candidates considered for next token.
- **top P**: %ge of most-likely candidates considered for next token
- **embeddings**: numerical representations of words
- **image_uri**: Docker image URI in Amazon SageMaker AI
- **inference_instances**: list of inference instances for a model deployed in Amazon SageMaker AI
- **supervised learning**: train models on labeled data to recognize and classify objects
- **unsupervised learning**: detect anomalies or unusual patterns
- **semi-supervised learning**: combines a small amount of labeled data with a large amount of unlabeled data. Semi-supervised learning is useful to train models to recognize different driving scenarios that might not be fully la